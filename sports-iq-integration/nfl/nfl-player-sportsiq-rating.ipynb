{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b52d4f0f",
   "metadata": {},
   "source": [
    "## NFL PLayer WAR\n",
    "\n",
    "Create a SportsIQ Score (WAR type). This score should range from 0 - 100 scale\n",
    "\n",
    "This will take into account a players:\n",
    "- EPA / Play\n",
    "- Success Rate\n",
    "- CPOE (QB)\n",
    "- YPRR (WR / TE)\n",
    "- Pass block / run block grades (OL)\n",
    "- Pressure rate (DL / EDGE)\n",
    "- win rate (DL / EDGE)\n",
    "- Coverage success / penalties (DB)\n",
    "- Special teams snaps\n",
    "- Field Goal Made / Missed (K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "fc1636a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nflreadpy as nfl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, Any\n",
    "import os\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "35287976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_master_with_cache(cache_file='nfl_player_master_2025.csv', cache_hours=24):\n",
    "    \"\"\"\n",
    "    Load df_master from cache if available and recent, otherwise regenerate.\n",
    "    \n",
    "    Args:\n",
    "        cache_file: Name of CSV file to cache to\n",
    "        cache_hours: Number of hours before cache expires (default: 24)\n",
    "    \n",
    "    Returns:\n",
    "        df_master: The loaded/generated DataFrame\n",
    "        from_cache: Boolean indicating if data came from cache\n",
    "    \"\"\"\n",
    "    print(f\"\\nChecking for cached df_master in '{cache_file}'...\")\n",
    "\n",
    "    # Check if cache file exists and is fresh\n",
    "    if os.path.exists(cache_file):\n",
    "        file_age = datetime.now() - datetime.fromtimestamp(os.path.getmtime(cache_file))\n",
    "        if file_age < timedelta(hours=cache_hours):\n",
    "            print(f\"✓ Loading from cache: {cache_file}\")\n",
    "            print(f\"  Cache age: {file_age.total_seconds() / 3600:.1f} hours\")\n",
    "            return pd.read_csv(cache_file), True\n",
    "        else:\n",
    "            print(f\"⊘ Cache expired ({file_age.total_seconds() / 3600:.1f} hours old), regenerating...\")\n",
    "    else:\n",
    "        print(f\"⊘ Cache file not found, generating new data...\")\n",
    "    \n",
    "    # Regenerate data\n",
    "    print(\"\\nLoading data from NFL API...\")\n",
    "    \n",
    "    # 1. Load Rosters\n",
    "    roster = nfl.load_rosters(seasons=[2025]).to_pandas()\n",
    "    roster_key = roster[['full_name', 'position', 'team', 'gsis_id', 'pfr_id', 'depth_chart_position']]\n",
    "    roster_key = roster_key[roster_key['gsis_id'].notna()]\n",
    "    roster_key = roster_key[roster_key['pfr_id'].notna()]\n",
    "    print(\"  ✓ Roster loaded\")\n",
    "    \n",
    "    # 2. Load Snap Counts\n",
    "    snaps = nfl.load_snap_counts(seasons=[2025]).to_pandas()\n",
    "    snaps_season = snaps.groupby('pfr_player_id')[['offense_snaps', 'defense_snaps', 'st_snaps']].sum().reset_index()\n",
    "    # Count unique games played per player\n",
    "    games_played = snaps.groupby('pfr_player_id')['week'].nunique().reset_index().rename(columns={'week': 'games_played'})\n",
    "    snaps_season = snaps_season.merge(games_played, on='pfr_player_id', how='left')\n",
    "    print(\"  ✓ Snap counts loaded\")\n",
    "    \n",
    "    # 3. Load Player Stats\n",
    "    player_stats = nfl.load_player_stats(seasons=[2025], summary_level='reg').to_pandas()\n",
    "    adv_def = nfl.load_pfr_advstats(seasons=[2025], summary_level='season', stat_type='def').to_pandas()\n",
    "    adv_pass = nfl.load_pfr_advstats(seasons=[2025], summary_level='season', stat_type='pass').to_pandas()\n",
    "    adv_rush = nfl.load_pfr_advstats(seasons=[2025], summary_level='season', stat_type='rush').to_pandas()\n",
    "    adv_rec = nfl.load_pfr_advstats(seasons=[2025], summary_level='season', stat_type='rec').to_pandas()\n",
    "    print(\"  ✓ Player stats loaded\")\n",
    "    \n",
    "    # 4. Merge all data\n",
    "    df_master = roster_key.copy()\n",
    "    df_master = df_master.merge(snaps_season, left_on='pfr_id', right_on='pfr_player_id', how='left')\n",
    "    df_master = df_master.merge(player_stats, left_on='gsis_id', right_on='player_id', how='left')\n",
    "    df_master = df_master.merge(adv_def, on='pfr_id', how='left', suffixes=('', '_def'))\n",
    "    df_master = df_master.merge(adv_pass, on='pfr_id', how='left', suffixes=('', '_pass'))\n",
    "    df_master = df_master.merge(adv_rush, on='pfr_id', how='left', suffixes=('', '_rush'))\n",
    "    df_master = df_master.merge(adv_rec, on='pfr_id', how='left', suffixes=('', '_rec'))\n",
    "    print(\"  ✓ Data merged\")\n",
    "    \n",
    "    # 5. Clean up\n",
    "    df_master = df_master.drop_duplicates(subset=['gsis_id'], keep='first')\n",
    "    df_master = df_master[(df_master['offense_snaps'] > 0) | (df_master['defense_snaps'] > 0) | (df_master['st_snaps'] > 0)]\n",
    "    df_master = df_master.dropna(subset=['offense_snaps', 'defense_snaps', 'st_snaps'])\n",
    "    print(\"  ✓ Data cleaned\")\n",
    "    \n",
    "    # Save to cache\n",
    "    df_master.to_csv(cache_file, index=False)\n",
    "    print(f\"✓ Data saved to cache: {cache_file}\")\n",
    "    \n",
    "    return df_master, False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "cdc81ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for cached df_master in 'nfl_player_master_2025.csv'...\n",
      "✓ Loading from cache: nfl_player_master_2025.csv\n",
      "  Cache age: 1.1 hours\n"
     ]
    }
   ],
   "source": [
    "# Load or generate df_master\n",
    "df_master, from_cache = load_df_master_with_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "ba913630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.b Deduplicate by unique player (gsis_id), keeping first occurrence\n",
    "df_master = df_master.drop_duplicates(subset=['gsis_id'], keep='first')\n",
    "\n",
    "# Remove players with 0 snaps or null values\n",
    "df_master = df_master[(df_master['offense_snaps'] > 0) | (df_master['defense_snaps'] > 0) | (df_master['st_snaps'] > 0)]\n",
    "df_master = df_master.dropna(subset=['offense_snaps', 'defense_snaps', 'st_snaps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "57330d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1780, 231)"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_master.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "c0592c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for duplicates by full_name:\n",
      "\n",
      "Found 3 players with multiple rows:\n",
      "full_name\n",
      "Jordan Phillips    2\n",
      "Jaylon Jones       2\n",
      "Byron Young        2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Joe Flacco rows:\n",
      "    full_name     gsis_id    pfr_id team depth_chart_position\n",
      "5  Joe Flacco  00-0026158  FlacJo00  CIN                   QB\n",
      "\n",
      "\n",
      "Column names:\n",
      "['full_name', 'position_x', 'team', 'gsis_id', 'pfr_id', 'depth_chart_position', 'pfr_player_id', 'offense_snaps', 'defense_snaps', 'st_snaps', 'games_played', 'player_id', 'player_name', 'player_display_name', 'position_y', 'position_group', 'headshot_url', 'season', 'season_type', 'recent_team', 'games', 'completions', 'attempts', 'passing_yards', 'passing_tds', 'passing_interceptions', 'sacks_suffered', 'sack_yards_lost', 'sack_fumbles', 'sack_fumbles_lost', 'passing_air_yards', 'passing_yards_after_catch', 'passing_first_downs', 'passing_epa', 'passing_cpoe', 'passing_2pt_conversions', 'pacr', 'carries', 'rushing_yards', 'rushing_tds', 'rushing_fumbles', 'rushing_fumbles_lost', 'rushing_first_downs', 'rushing_epa', 'rushing_2pt_conversions', 'receptions', 'targets', 'receiving_yards', 'receiving_tds', 'receiving_fumbles', 'receiving_fumbles_lost', 'receiving_air_yards', 'receiving_yards_after_catch', 'receiving_first_downs', 'receiving_epa', 'receiving_2pt_conversions', 'racr', 'target_share', 'air_yards_share', 'wopr', 'special_teams_tds', 'def_tackles_solo', 'def_tackles_with_assist', 'def_tackle_assists', 'def_tackles_for_loss', 'def_tackles_for_loss_yards', 'def_fumbles_forced', 'def_sacks', 'def_sack_yards', 'def_qb_hits', 'def_interceptions', 'def_interception_yards', 'def_pass_defended', 'def_tds', 'def_fumbles', 'def_safeties', 'misc_yards', 'fumble_recovery_own', 'fumble_recovery_yards_own', 'fumble_recovery_opp', 'fumble_recovery_yards_opp', 'fumble_recovery_tds', 'penalties', 'penalty_yards', 'punt_returns', 'punt_return_yards', 'kickoff_returns', 'kickoff_return_yards', 'fg_made', 'fg_att', 'fg_missed', 'fg_blocked', 'fg_long', 'fg_pct', 'fg_made_0_19', 'fg_made_20_29', 'fg_made_30_39', 'fg_made_40_49', 'fg_made_50_59', 'fg_made_60_', 'fg_missed_0_19', 'fg_missed_20_29', 'fg_missed_30_39', 'fg_missed_40_49', 'fg_missed_50_59', 'fg_missed_60_', 'fg_made_list', 'fg_missed_list', 'fg_blocked_list', 'fg_made_distance', 'fg_missed_distance', 'fg_blocked_distance', 'pat_made', 'pat_att', 'pat_missed', 'pat_blocked', 'pat_pct', 'gwfg_made', 'gwfg_att', 'gwfg_missed', 'gwfg_blocked', 'gwfg_distance_list', 'fantasy_points', 'fantasy_points_ppr', 'season_def', 'player', 'tm', 'age', 'pos', 'g', 'gs', 'int', 'tgt', 'cmp', 'cmp_percent', 'yds', 'yds_cmp', 'yds_tgt', 'td', 'rat', 'dadot', 'air', 'yac', 'bltz', 'hrry', 'qbkd', 'sk', 'prss', 'comb', 'm_tkl', 'm_tkl_percent', 'loaded', 'bats', 'player_pass', 'team_pass', 'pass_attempts', 'throwaways', 'spikes', 'drops', 'drop_pct', 'bad_throws', 'bad_throw_pct', 'season_pass', 'pocket_time', 'times_blitzed', 'times_hurried', 'times_hit', 'times_pressured', 'pressure_pct', 'batted_balls', 'on_tgt_throws', 'on_tgt_pct', 'rpo_plays', 'rpo_yards', 'rpo_pass_att', 'rpo_pass_yards', 'rpo_rush_att', 'rpo_rush_yards', 'pa_pass_att', 'pa_pass_yards', 'intended_air_yards', 'intended_air_yards_per_pass_attempt', 'completed_air_yards', 'completed_air_yards_per_completion', 'completed_air_yards_per_pass_attempt', 'pass_yards_after_catch', 'pass_yards_after_catch_per_completion', 'scrambles', 'scramble_yards_per_attempt', 'season_rush', 'player_rush', 'tm_rush', 'age_rush', 'pos_rush', 'g_rush', 'gs_rush', 'att', 'yds_rush', 'td_rush', 'x1d', 'ybc', 'ybc_att', 'yac_rush', 'yac_att', 'brk_tkl', 'att_br', 'loaded_rush', 'season_rec', 'player_rec', 'tm_rec', 'age_rec', 'pos_rec', 'g_rec', 'gs_rec', 'tgt_rec', 'rec', 'yds_rec', 'td_rec', 'x1d_rec', 'ybc_rec', 'ybc_r', 'yac_rec', 'yac_r', 'adot', 'brk_tkl_rec', 'rec_br', 'drop', 'drop_percent', 'int_rec', 'rat_rec', 'loaded_rec']\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "print(\"Checking for duplicates by full_name:\")\n",
    "duplicate_names = df_master['full_name'].value_counts()\n",
    "duplicates = duplicate_names[duplicate_names > 1]\n",
    "print(f\"\\nFound {len(duplicates)} players with multiple rows:\")\n",
    "print(duplicates)\n",
    "\n",
    "# Show Joe Flacco example\n",
    "print(\"\\n\\nJoe Flacco rows:\")\n",
    "print(df_master[df_master['full_name'] == 'Joe Flacco'][['full_name', 'gsis_id', 'pfr_id', 'team', 'depth_chart_position']])\n",
    "\n",
    "print(\"\\n\\nColumn names:\")\n",
    "print(df_master.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "fed09940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining duplicates - checking if they're different players:\n",
      "\n",
      "\n",
      "Jordan Phillips:\n",
      "            full_name     gsis_id    pfr_id team position_x  \\\n",
      "68    Jordan Phillips  00-0031557  PhilJo01  BUF         DL   \n",
      "1578  Jordan Phillips  00-0040175  PhilJo02  MIA         DL   \n",
      "\n",
      "     depth_chart_position  \n",
      "68                     DT  \n",
      "1578                   DT  \n",
      "\n",
      "Jaylon Jones:\n",
      "         full_name     gsis_id    pfr_id team position_x depth_chart_position\n",
      "813   Jaylon Jones  00-0037106  JoneJa12  CHI         DB                   CB\n",
      "1042  Jaylon Jones  00-0038407  JoneJa13  IND         DB                   CB\n",
      "\n",
      "Byron Young:\n",
      "        full_name     gsis_id    pfr_id team position_x depth_chart_position\n",
      "1198  Byron Young  00-0038978  YounBy00  PHI         DL                   DT\n",
      "1243  Byron Young  00-0039137  YounBy01   LA         LB                  OLB\n"
     ]
    }
   ],
   "source": [
    "# Examine remaining duplicates to understand if they're legitimate\n",
    "print(\"Remaining duplicates - checking if they're different players:\\n\")\n",
    "for dup_name in ['Jordan Phillips', 'Jaylon Jones', 'Byron Young']:\n",
    "    print(f\"\\n{dup_name}:\")\n",
    "    dup_rows = df_master[df_master['full_name'] == dup_name][['full_name', 'gsis_id', 'pfr_id', 'team', 'position_x', 'depth_chart_position']]\n",
    "    print(dup_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "ea0eb347",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionScorer(ABC):\n",
    "    \"\"\"\n",
    "    Scores players based on weighted Z-scores, normalized to a 0-100 scale.\n",
    "    Weights do NOT need to sum to 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, position: str):\n",
    "        self.position = position\n",
    "        \n",
    "    @abstractmethod\n",
    "    def filter_players(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Filter the DataFrame to only include relevant players for this position.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def compute_metrics(self, row: pd.Series) -> Dict[str, float]:\n",
    "        \"\"\"Extract raw stats from a row.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_config(self) -> Dict[str, Dict[str, float]]:\n",
    "        \"\"\"\n",
    "        Configuration for metrics.\n",
    "        - 'weight': Relative importance (e.g., 10.0 for huge impact, 1.0 for minor).\n",
    "        - 'direction': 1 (Higher is Better) or -1 (Lower is Better).\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def _calculate_raw_score(self, row: pd.Series, peer_stats: pd.DataFrame, config: Dict) -> float:\n",
    "        \"\"\"Internal helper to calculate the raw weighted sum.\"\"\"\n",
    "        raw_score = 0.0\n",
    "        \n",
    "        for metric, conf in config.items():\n",
    "            val = self.compute_metrics(row).get(metric, 0)\n",
    "            weight = conf['weight']\n",
    "            direction = conf['direction']\n",
    "            \n",
    "            # Get peer distribution for this specific metric\n",
    "            # (In production, cache these means/stds to speed up)\n",
    "            peer_vals = peer_stats.apply(lambda r: self.compute_metrics(r).get(metric, 0), axis=1)\n",
    "            \n",
    "            if len(peer_vals) > 1 and np.std(peer_vals) > 0:\n",
    "                mean = np.mean(peer_vals)\n",
    "                std = np.std(peer_vals)\n",
    "                z_score = (val - mean) / std\n",
    "            else:\n",
    "                z_score = 0.0\n",
    "                \n",
    "            # Add to total: Z-Score * Weight * Direction\n",
    "            # Example: Bad Throw (Z=2.0) * Weight(5) * Dir(-1) = -10.0 impact\n",
    "            raw_score += (z_score * weight * direction)\n",
    "            \n",
    "        return raw_score\n",
    "\n",
    "    def score_all(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Scores all players and returns detailed breakdown of what adds up to raw_score.\n",
    "        \"\"\"\n",
    "        # Filter for this position\n",
    "        peers = df[df['depth_chart_position'] == self.position].copy()\n",
    "\n",
    "        print(f\"\\nScoring position: {self.position} with {len(peers)} players\")\n",
    "        \n",
    "        if peers.empty:\n",
    "            return peers\n",
    "\n",
    "        config = self.get_config()\n",
    "        metric_names = list(config.keys())\n",
    "        \n",
    "        # 1. Compute raw metrics for all peers at once\n",
    "        metrics_df = peers.apply(lambda r: pd.Series(self.compute_metrics(r)), axis=1)\n",
    "        metrics_df = metrics_df.reindex(columns=metric_names)\n",
    "\n",
    "        print(f\"Metrics DataFrame shape: {metrics_df.shape}\")\n",
    "\n",
    "        # Remove player with filter method\n",
    "        metrics_df = self.filter_players(metrics_df)\n",
    "        if metrics_df.empty:\n",
    "            return metrics_df\n",
    "        \n",
    "        print(f\"Filtered Metrics DataFrame shape: {metrics_df.shape}\")\n",
    "        \n",
    "        # 2. Calculate peer distribution (mean/std) per metric\n",
    "        means = metrics_df.mean(skipna=True)\n",
    "        stds = metrics_df.std(ddof=0, skipna=True)  # Population std\n",
    "        \n",
    "        # 3. Compute z-scores (fill NaN with 0 when std=0)\n",
    "        z_scores_df = (metrics_df - means) / stds.replace(0, np.nan)\n",
    "        z_scores_df = z_scores_df.fillna(0.0)\n",
    "        \n",
    "        # 4. Compute weighted directional contributions per metric\n",
    "        weights = pd.Series({m: config[m]['weight'] for m in metric_names})\n",
    "        directions = pd.Series({m: config[m]['direction'] for m in metric_names})\n",
    "        contrib_df = z_scores_df.multiply(weights, axis=1).multiply(directions, axis=1)\n",
    "        \n",
    "        # 5. Raw score is sum of contributions\n",
    "        peers['raw_score'] = contrib_df.sum(axis=1)\n",
    "        \n",
    "        # 6. Convert to T-Score (0-100 scale)\n",
    "        raw_mean = peers['raw_score'].mean()\n",
    "        raw_std = peers['raw_score'].std()\n",
    "        \n",
    "        if raw_std == 0:\n",
    "            peers['SportsIQ'] = 50.0\n",
    "        else:\n",
    "            peers['SportsIQ'] = ((peers['raw_score'] - raw_mean) / raw_std) * 10 + 50\n",
    "        \n",
    "        peers['SportsIQ'] = peers['SportsIQ'].clip(0, 99)\n",
    "        \n",
    "        # 7. Attach all breakdown columns\n",
    "        peers = peers.join(metrics_df.add_prefix('metric_'))\n",
    "        peers = peers.join(z_scores_df.add_prefix('z_'))\n",
    "        peers = peers.join(contrib_df.add_prefix('contrib_'))\n",
    "        \n",
    "        # Return in logical order: identifiers → scores → breakdown\n",
    "        result_cols = (\n",
    "            ['player_name', 'depth_chart_position', 'SportsIQ', 'raw_score']\n",
    "            + [f'metric_{m}' for m in metric_names]\n",
    "            + [f'z_{m}' for m in metric_names]\n",
    "            + [f'contrib_{m}' for m in metric_names]\n",
    "        )\n",
    "        return peers[[c for c in result_cols if c in peers.columns]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "9c09d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QB Scorer\n",
    "\n",
    "class QBScorer(PositionScorer):\n",
    "\tdef __init__(self): super().__init__(\"QB\")\n",
    "\n",
    "\tdef filter_players(self, df):\n",
    "\t\t\t# Filter to QBs with at least 100 passing attempts\n",
    "\t\t\treturn df[df['attempts'] >= 50]\n",
    "\n",
    "\tdef compute_metrics(self, row):\n",
    "\t\tatts = max(1, row.get('pass_attempts', 1))\n",
    "\t\tsnaps = max(1, row.get('offense_snaps', 1))\n",
    "\t\tgames_played = max(1, row.get('games_played', 1))\n",
    "\t\treturn {\n",
    "\t\t\t'epa_per_play': row.get('passing_epa', 0), # EPA is already per-play usually\n",
    "\t\t\t'cpoe': row.get('passing_cpoe', 0),\n",
    "\t\t\t'bad_throw_pct': row.get('bad_throws', 0) / atts,\n",
    "\t\t\t'sack_pct': row.get('sacks_suffered', 0) / snaps,\n",
    "\t\t\t'interception_pct': row.get('passing_interceptions', 0) / atts,\n",
    "\t\t\t'air_yards': row.get('intended_air_yards_per_pass_attempt', 0),\n",
    "\t\t\t'accuracy': row.get('on_tgt_throws', 0) / atts,\n",
    "\t\t\t'attempts': atts,\n",
    "\t\t\t'pacr': row.get('pacr', 0) ,\n",
    "\t\t\t'passing_td_per_game': row.get('passing_tds', 0) / games_played,\n",
    "\t\t\t'completions_pct': row.get('completions', 0) / atts,\n",
    "\t\t}\n",
    "\n",
    "\tdef get_config(self):\n",
    "\t\treturn {\n",
    "\t\t\t'epa_per_play':    \t\t\t{'weight': 9.0, 'direction': 1},\n",
    "\t\t\t'pacr': \t\t\t\t\t{'weight': 7.0, 'direction': 1},\n",
    "\t\t\t'bad_throw_pct':   \t\t\t{'weight': 7.0, 'direction': -1},  \n",
    "\t\t\t'air_yards': \t\t\t\t{'weight': 6.0, 'direction': 1},\n",
    "\t\t\t'passing_td_per_game' : \t{'weight': 5.0, 'direction': 1},\n",
    "\t\t\t'cpoe':            \t\t\t{'weight': 5.0, 'direction': 1},\n",
    "\t\t\t'attempts':        \t\t\t{'weight': 4.0, 'direction': 1},\n",
    "\t\t\t'sack_pct':        \t\t\t{'weight': 3.0, 'direction': -1},\n",
    "\t\t\t'completions_pct': \t\t\t{'weight': 3.0, 'direction': 1},\n",
    "\t\t\t'interception_pct': \t\t{'weight': 3.0, 'direction': -1},\n",
    "\t\t\t'accuracy':        \t\t\t{'weight': 2.0, 'direction': 1}\n",
    "\t\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "e00e2a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RB Scorer \n",
    "    \n",
    "class RBScorer(PositionScorer):\n",
    "\tdef __init__(self): super().__init__(\"RB\")\n",
    "\n",
    "\tdef filter_players(self, df):\n",
    "\t\t# Filter to RBs with at least 50 carries\n",
    "\t\treturn df[df['carries'] >= 50]\n",
    "\n",
    "\tdef compute_metrics(self, row):\n",
    "\t\tcarries = max(1, row.get('carries', 1))\n",
    "\t\tgames_played = max(1, row.get('games_played', 1))\t\n",
    "\t\treturn {\n",
    "\t\t\t'rushing_epa': row.get('rushing_epa', 0), # EPA is already per-play usually\n",
    "\t\t\t'receiving_epa': row.get('receiving_epa', 0),\n",
    "\t\t\t'yac_att': row.get('yac_att', 0),\n",
    "\t\t\t'rushing_yards': row.get('rushing_yards', 0),\n",
    "\t\t\t'receiving_yards': row.get('receiving_yards', 0),\n",
    "\t\t\t'rushing_first_downs': row.get('rushing_first_downs', 0),\n",
    "\t\t\t'rushing_tds': row.get('rushing_tds', 0),\n",
    "\t\t\t'broken_tackles': row.get('brk_tkl', 0),\n",
    "\t\t\t'receiving_yards_after_catch': row.get('receiving_yards_after_catch', 0),\n",
    "\t\t\t'fumbles': row.get('rushing_fumbles', 0),\n",
    "\t\t\t'drop_percent': row.get('drop_percent', 0),\n",
    "\t\t\t'carries': carries,\n",
    "\t\t\t'carries_per_game': carries / games_played\n",
    "\t\t}\n",
    "\n",
    "\tdef get_config(self):\n",
    "\t\treturn {\n",
    "\t\t\t# --- Elite Efficiency (The \"Talent\" Metrics) ---\n",
    "\t\t\t# EPA measures actual value added. Crucial for separating empty yards from impactful ones.\n",
    "\t\t\t'rushing_epa':          {'weight': 8.0, 'direction': 1},\n",
    "\t\t\t'receiving_epa':        {'weight': 6.0, 'direction': 1},\n",
    "\t\t\t\n",
    "\t\t\t# Yards After Contact per Attempt (yac_att). \n",
    "\t\t\t# This is the single best stat for isolating the RB's skill from the O-Line's blocking.\n",
    "\t\t\t'yac_att':              {'weight': 7.0, 'direction': 1},\n",
    "\n",
    "\t\t\t# --- Production & Volume (The \"Workhorse\" Metrics) ---\n",
    "\t\t\t# We value yards, but weight them slightly lower than EPA to avoid just rewarding pure volume.\n",
    "\t\t\t'rushing_yards':        {'weight': 6.0, 'direction': 1},\n",
    "\t\t\t'receiving_yards':      {'weight': 4.0, 'direction': 1},\n",
    "\t\t\t\n",
    "\t\t\t# Moving the chains is a key skill for a starter.\n",
    "\t\t\t'rushing_first_downs':  {'weight': 5.0, 'direction': 1},\n",
    "\t\t\t'rushing_tds':          {'weight': 3.0, 'direction': 1},\n",
    "\n",
    "\t\t\t# --- Playmaking & Skill ---\n",
    "\t\t\t# Broken Tackles (broken_tackles) shows elusiveness and power.\n",
    "\t\t\t'broken_tackles':              {'weight': 4.0, 'direction': 1},\n",
    "\t\t\t# Yards After Catch (receiving_yards_after_catch) rewards RBs who turn checkdowns into gains.\n",
    "\t\t\t'receiving_yards_after_catch': {'weight': 3.0, 'direction': 1},\n",
    "\n",
    "\t\t\t# --- Negatives ---\n",
    "\t\t\t# Fumbles are the quickest way to lose a job.\n",
    "\t\t\t'fumbles':     \t\t\t{'weight': 5.0, 'direction': -1},\n",
    "\t\t\t# Drops in the passing game kill drive momentum.\n",
    "\t\t\t'drop_percent':         {'weight': 2.5, 'direction': -1},\n",
    "\t\t\t\n",
    "\t\t\t# --- Filter / Bonus ---\n",
    "\t\t\t# You might add a small weight to 'carries_per_game' if you specifically want to find high-volume starters.\n",
    "\t\t\t'carries'\t:                 \t\t{'weight': 0, 'direction': 1},\n",
    "\t\t\t'carries_per_game':              {'weight': 2.0, 'direction': 1}\n",
    "\t\t}    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "d3b3addf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OLScorer(PositionScorer):\n",
    "    def __init__(self): super().__init__(\"OL\")\n",
    "    \n",
    "    def compute_metrics(self, row):\n",
    "        snaps = max(1, row.get('offense_snaps', 1))\n",
    "        return {\n",
    "            'blown_block_rate': (row.get('sacks_allowed', 0) + row.get('hits_allowed', 0)) / snaps,\n",
    "            'penalty_rate': row.get('penalties', 0) / snaps,\n",
    "            'snap_count': row.get('offense_snaps', 0)\n",
    "        }\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            # Massive Penalties for failure\n",
    "            'blown_block_rate': {'weight': 15.0, 'direction': -1}, \n",
    "            'penalty_rate':     {'weight': 8.0,  'direction': -1},\n",
    "            \n",
    "            # Small positive weight just for being a starter (Availability)\n",
    "            'snap_count':       {'weight': 2.0,  'direction': 1} \n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "3e9eca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLScorer(PositionScorer):\n",
    "    def __init__(self): super().__init__(\"DL\")\n",
    "    \n",
    "    def compute_metrics(self, row):\n",
    "        snaps = max(1, row.get('defense_snaps', 1))\n",
    "        return {\n",
    "            'pressure_rate': row.get('pressures', 0) / snaps,\n",
    "            'sack_conversion': row.get('sacks', 0) / max(1, row.get('pressures', 1)), # How often do they finish?\n",
    "            'missed_tackle_rate': row.get('missed_tackles', 0) / snaps,\n",
    "        }\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            # Pressure is the best predictor of skill\n",
    "            'pressure_rate':      {'weight': 12.0, 'direction': 1},\n",
    "            \n",
    "            # Finishing is high value but high variance\n",
    "            'sack_conversion':    {'weight': 5.0,  'direction': 1},\n",
    "            \n",
    "            # Mistakes\n",
    "            'missed_tackle_rate': {'weight': 4.0,  'direction': -1}\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "id": "9b2a8bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring position: QB with 81 players\n",
      "Metrics DataFrame shape: (81, 11)\n",
      "Filtered Metrics DataFrame shape: (56, 11)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Usage\n",
    "qb_scorer = QBScorer()\n",
    "scored_df = qb_scorer.score_all(df_master)\n",
    "scored_df.sort_values('SportsIQ', ascending=False).to_csv('nfl_qb_sportsiq_2025.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "id": "c33ccf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring position: RB with 151 players\n",
      "Metrics DataFrame shape: (151, 13)\n",
      "Filtered Metrics DataFrame shape: (65, 13)\n"
     ]
    }
   ],
   "source": [
    "rb_scorer = RBScorer()\n",
    "scored_df = rb_scorer.score_all(df_master)\n",
    "scored_df.sort_values('SportsIQ', ascending=False).to_csv('nfl_rb_sportsiq_2025.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "id": "3b1581a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def score_all_players(stats_df: pd.DataFrame, position_col: str = 'depth_chart_position') -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Score all players using position-specific scorers.\n",
    "    \n",
    "#     Args:\n",
    "#         stats_df: DataFrame with player stats\n",
    "#         position_col: Name of position column\n",
    "    \n",
    "#     Returns:\n",
    "#         DataFrame with 'sportsiq_score' column added\n",
    "#     \"\"\"\n",
    "#     stats_df = stats_df.copy()\n",
    "#     stats_df['sportsiq_score'] = 0.0\n",
    "    \n",
    "#     for position in stats_df[position_col].unique():\n",
    "#         if pd.isna(position):\n",
    "#             continue\n",
    "        \n",
    "#         # Get scorer for this position (fallback to generic if not found)\n",
    "#         scorer = POSITION_SCORERS.get(str(position).upper())\n",
    "#         if scorer is None:\n",
    "#             print(f\"Warning: No scorer for position {position}, skipping\")\n",
    "#             continue\n",
    "        \n",
    "#         # Get all players at this position for peer normalization\n",
    "#         position_mask = stats_df[position_col] == position\n",
    "#         peer_stats = stats_df[position_mask]\n",
    "        \n",
    "#         # Score each player\n",
    "#         scores = []\n",
    "#         for idx, row in peer_stats.iterrows():\n",
    "#             try:\n",
    "#                 score = scorer.score_player(row, peer_stats)\n",
    "#                 scores.append(score)\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error scoring {row.get('player_name', 'unknown')}: {e}\")\n",
    "#                 scores.append(np.nan)\n",
    "        \n",
    "#         stats_df.loc[position_mask, 'sportsiq_score'] = scores\n",
    "#         print(f\"Scored {len(scores)} {position} players\")\n",
    "    \n",
    "#     return stats_df\n",
    "\n",
    "# # Score all players\n",
    "# data_scored = score_all_players(df_master)\n",
    "# data_scored[['player_name', 'depth_chart_position', 'sportsiq_score']].head(20)\n",
    "\n",
    "# data_scored[['player_name', 'depth_chart_position', 'sportsiq_score']].to_csv('nfl_player_war_2025.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
